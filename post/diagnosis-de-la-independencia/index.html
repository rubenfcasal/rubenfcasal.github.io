<!DOCTYPE html>
<html lang="es">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.30.2" />
  <meta name="author" content="Ruben Fernandez-Casal">
  <meta name="description" content="Associate Professor (Contratado Doctor) of Statistics and Operational Research (Estadística e Investigación Operativa)">

  
  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="/css/highlight.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  


  

  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  

  <link rel="alternate" href="" type="application/rss+xml" title="R Machinery">
  <link rel="feed" href="" type="application/rss+xml" title="R Machinery">

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png">

  <link rel="canonical" href="/post/diagnosis-de-la-independencia/">

  

  <title>Diagnosis de la independencia | R Machinery</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Barra de navegación</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/"><img src="/img/rmach.png" alt="R Machinery"></a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      <ul class="nav navbar-nav navbar-right">
        

        

        <li class="nav-item">
          <a href="/post">
            
            <span>Blog</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="https://rubenfcasal.github.io/npsp">
            
            <span>npsp</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#about">
            
            <span>CV</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contacto</span>
          </a>
        </li>

        
        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Diagnosis de la independencia</h1>
    

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2017-10-23 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      2017-10-23
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    10 
  </span>
  

  
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fa fa-folder"></i>
    
    <a href="/categories/r">R</a
    >, 
    
    <a href="/categories/apuntes">Apuntes</a
    >
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Diagnosis%20de%20la%20independencia&amp;url=%2fpost%2fdiagnosis-de-la-independencia%2f"
         target="_blank">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fdiagnosis-de-la-independencia%2f"
         target="_blank">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fdiagnosis-de-la-independencia%2f&amp;title=Diagnosis%20de%20la%20independencia"
         target="_blank">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fdiagnosis-de-la-independencia%2f&amp;title=Diagnosis%20de%20la%20independencia"
         target="_blank">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Diagnosis%20de%20la%20independencia&amp;body=%2fpost%2fdiagnosis-de-la-independencia%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

    <div class="article-style" itemprop="articleBody">
      <div id="TOC">
<ul>
<li><a href="#introduccion">Introducción</a><ul>
<li><a href="#repaso-la-covarianza-y-el-coeficiente-de-correlacion">Repaso: La covarianza y el coeficiente de correlación</a></li>
<li><a href="#el-problema-de-la-dependencia">El problema de la dependencia</a></li>
<li><a href="#metodos-para-detectar-dependencia">Métodos para detectar dependencia</a></li>
</ul></li>
<li><a href="#metodos-graficos">Métodos gráficos</a><ul>
<li><a href="#grafico-secuencial">Gráfico secuencial</a></li>
<li><a href="#grafico-de-dispersion-retardado">Gráfico de dispersion retardado</a></li>
<li><a href="#el-correlograma">El correlograma</a></li>
</ul></li>
<li><a href="#contrastes-de-hipotesis">Contrastes de hipótesis</a><ul>
<li><a href="#test-de-rachas">Test de rachas</a></li>
<li><a href="#el-contraste-de-ljung-box">El contraste de Ljung-Box</a></li>
</ul></li>
<li><a href="#ejemplo-adicional-analisis-de-series-temporales">Ejemplo adicional: Análisis de series temporales</a></li>
</ul>
</div>

<p><br></p>
<div id="introduccion" class="section level1">
<h1>Introducción</h1>
<div id="repaso-la-covarianza-y-el-coeficiente-de-correlacion" class="section level2">
<h2>Repaso: La covarianza y el coeficiente de correlación</h2>
<p>Para medir la relación (lineal) entre dos variables se emplea la covarianza: <span class="math display">\[Cov(X,Y) = E{\big[(X - E(X))(Y - E(Y))\big]}\]</span> Su estimador es la covarianza muestral: <span class="math display">\[s_{XY}=\frac{1}{n}\sum_{i=1}^{n}(x_{i}-\overline{x})(y_{i} - \overline{y})\]</span></p>
<ul>
<li><p>Si dos variables son idependientes su covarianza es nula. El reciproco no es cierto en general, si dos variables tienen covarianza nula se dice que son incorreladas (no hay relación lineal, aunque puede haber una relación no lineal).</p></li>
<li><p>Si la covarianza es positiva indica que a valores grandes de X le corresponden valores grandes de Y (i.e. al incrementar X se incrementa Y) y se dice que hay una relación lineal positiva.</p></li>
<li><p>Si la covarianza es negativa indica que a valores grandes de X le corresponden valores pequeños de Y (i.e. al incrementar X, Y disminuye) y se dice que hay una relación lineal negativa.</p></li>
</ul>
<p>Cuanto mayor es el valor (absoluto) de la covarianza, mayor es el grado de relación lineal entre las variables. Sin embargo, su valor depende de las escala de las variables por lo que es difícil determinar cuando es grande o pequeña. Para medir el grado de relación lineal puede ser preferible reescalarla, i.e. emplear el coeficiente de correlación: <span class="math display">\[\rho\left( X, Y \right)  =\frac{Cov\left( X, Y \right)    }
{\sigma\left( X \right)  \sigma\left( Y \right)}\]</span></p>
<p>Su estimador es el correlograma muestral: <span class="math display">\[r_{XY}=\frac{\sum_{i=1}^{n}(x_i-\overline{x})(y_i-\overline{y})}
    {\sqrt{ \sum_{i=1}^{n}(x_i-\overline{x})^{2}} 
    \sqrt{\sum_{i=1}^{n}(y_i-\overline{y})^{2}}}\]</span></p>
<div id="matriz-de-covarianzas" class="section level4">
<h4>Matriz de covarianzas</h4>
<p>Cuando consideramos <span class="math inline">\(d\)</span> variables aleatorias,<br />
<span class="math display">\[\mathbf{Y} = \left( Y_{1},Y_{2},\ldots ,Y_{d}\right),\]</span> se trabaja con la matriz de covarianzas: <span class="math display">\[\Sigma = E{\big[(\mathbf{Y} - E(\mathbf{Y}))(\mathbf{Y} - E(\mathbf{Y}))^t \big]}\]</span> donde <span class="math inline">\(\sigma_{ij} = Cov(Y_i,Y_j)\)</span> (también se denomina matriz de varianzas-covarianzas)</p>
</div>
<div id="ejemplo-datos-simulados" class="section level4">
<h4>Ejemplo: datos simulados</h4>
<p>Consideramos un proceso temporal estacionario con dependencia exponencial:</p>
<pre class="r"><code>curve(exp(-x), 0, 2, xlab = &#39;distancia&#39;, ylab = &#39;covarianza&#39;, ylim = c(0,1))
abline(h = 0, v = 1, lty = 3)</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-1-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>(la dependencia entre las observaciones depende del “salto” entre ellas).</p>
<pre class="r"><code>n &lt;- 100          # Nº de observaciones
t &lt;- seq(0, 1, length = n)
mu &lt;- rep(0, n)   # Media
# mu &lt;- 0.25 + 0.5*t
# mu &lt;- sin(2*pi*t)

# Matriz de covarianzas
t.dist &lt;- as.matrix(dist(t))
t.cov &lt;- exp(-t.dist)
str(t.cov)</code></pre>
<pre><code>##  num [1:100, 1:100] 1 0.99 0.98 0.97 0.96 ...
##  - attr(*, &quot;dimnames&quot;)=List of 2
##   ..$ : chr [1:100] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   ..$ : chr [1:100] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...</code></pre>
<pre class="r"><code>t.cov[1:5, 1:5] # Covarianzas de las 5 primeras observaciones</code></pre>
<pre><code>##           1         2         3         4         5
## 1 1.0000000 0.9899498 0.9800007 0.9701515 0.9604013
## 2 0.9899498 1.0000000 0.9899498 0.9800007 0.9701515
## 3 0.9800007 0.9899498 1.0000000 0.9899498 0.9800007
## 4 0.9701515 0.9800007 0.9899498 1.0000000 0.9899498
## 5 0.9604013 0.9701515 0.9800007 0.9899498 1.0000000</code></pre>
<pre class="r"><code># Simulación de las observaciones
set.seed(1)
library(MASS)

z &lt;- rnorm(n)
y1 &lt;- mu + z # Datos independientes
y2 &lt;- mvrnorm(1, mu, t.cov) # Datos dependientes

plot(t, mu, type=&quot;l&quot;, lwd = 2, ylim = c(-3,3), ylab = &#39;y&#39;)
lines(t, y1, col = &#39;blue&#39;)
lines(t, y2, col = &#39;red&#39;)
legend(&quot;bottomright&quot;, legend = c(&quot;Datos independientes&quot;, &quot;Datos dependientes&quot;), col = c(&#39;blue&#39;, &#39;red&#39;), lty = 1)</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="el-problema-de-la-dependencia" class="section level2">
<h2>El problema de la dependencia</h2>
<p>Los métodos “clásicos” de inferencia estadística se basan en suponer que las observaciones <span class="math inline">\(Y_{1},\ldots,Y_{n}\)</span> son una muestra aleatoria simple (m.a.s.) de <span class="math inline">\(Y\)</span>. Por tanto suponen que las observaciones son independientes (o los errores, en el caso de un modelo de regresión).</p>
<ul>
<li><p>La ausencia de aleatoriedad es difícil de corregir y puede influir notablemente en el análisis estadístico.</p></li>
<li><p>Si existe dependencia entre las observaciones muestrales (i.e. el conocimiento de <span class="math inline">\(Y_{i}\)</span> proporciona información sobre los valores de <span class="math inline">\(Y_{i+1}\)</span>, <span class="math inline">\(Y_{i+2}\)</span>, <span class="math inline">\(\ldots\)</span>), los métodos “clásicos” no serán en principio adecuados (pueden conducir a conclusiones erróneas).</p>
<ul>
<li><p>Esto es debido principalmente a que introduce un <strong>sesgo en los estimadores de las varianzas</strong> (obtenidos asumiendo independencia).</p></li>
<li><p>Los correspondientes intervalos de confianza y contrastes de hipótesis tendrán una confianza o una potencia distinta de la que deberían (aunque las estimaciones de los parámetros pueden no verse muy afectadas).</p></li>
</ul></li>
</ul>
<p>Si <span class="math inline">\(Y_{1}\)</span> e <span class="math inline">\(Y_{2}\)</span> son independientes (<span class="math inline">\(Cov(Y_{1},Y_{2})=0\)</span>): <span class="math display">\[Var(Y_{1}+Y_{2})=Var(Y_{1})+Var(Y_{2})\]</span></p>
<p>En el caso general (dependencia): <span class="math display">\[Var(Y_{1}+Y_{2})=Var(Y_{1})+Var(Y_{2})+2Cov(Y_{1},Y_{2})\]</span></p>
<p>Típicamente <span class="math inline">\(Cov(Y_{1},Y_{2})&gt;0\)</span> por lo que con los métodos “clásicos” (basados en independencia) se suelen producir subestimaciones de las varianzas (IC más estrechos y tendencia a rechazar <span class="math inline">\(H_{0}\)</span> en contrastes).</p>
<div id="ejemplo-datos-simulados-1" class="section level4">
<h4>Ejemplo: datos simulados</h4>
<p>En el caso anterior la varianza es uno con ambos procesos. Las estimaciones suponiendo independencia serían:</p>
<pre class="r"><code>var(y1)</code></pre>
<pre><code>## [1] 0.8067621</code></pre>
<pre class="r"><code>var(y2)</code></pre>
<pre><code>## [1] 0.1108155</code></pre>
<p>En el caso de datos dependientes se produce una clara subestimación de la varianza</p>
</div>
</div>
<div id="metodos-para-detectar-dependencia" class="section level2">
<h2>Métodos para detectar dependencia</h2>
<p>Es de esperar que datos cercanos en el tiempo (o en el espacio) sean más parecidos (dependientes) que datos más alejados <span class="math inline">\(\Rightarrow\)</span> <strong>dependencia temporal</strong> (espacial, espacio-temporal).</p>
<p>En este tema nos centraremos en el caso de dependencia temporal (unidimensional), más adelante trataremos el caso de dependecia espacial (bidimesional).</p>
<div id="metodos-para-detectar-dependencia-temporal" class="section level4">
<h4>Métodos para detectar dependencia temporal</h4>
<ul>
<li><p>Gráficos:</p>
<ul>
<li><p>Secuencial / Dispersión frente al tiempo</p></li>
<li><p>Dispersión retardado</p></li>
<li><p>Correlograma</p></li>
</ul></li>
<li><p>Contrastes:</p>
<ul>
<li><p>Tests basados en rachas</p></li>
<li><p>Test de Ljung-Box</p></li>
</ul></li>
</ul>
<hr />
</div>
</div>
</div>
<div id="metodos-graficos" class="section level1">
<h1>Métodos gráficos</h1>
<div id="grafico-secuencial" class="section level2">
<h2>Gráfico secuencial</h2>
<p>El gráfico de dispersión <span class="math inline">\(\{(i,Y_{i}) : i = 1, \ldots, n \}\)</span> permite detectar la presencia de un <strong>efecto temporal</strong>.</p>
<ul>
<li><p>Es importante mantener/guardar el orden de recogida de los datos.</p></li>
<li><p>Si existe una tendencia los datos no son homogéneos (debería tenerse en cuenta la variable índice, o tiempo, como variable explicativa). Podría indicar la presencia de un “efecto aprendizaje”.</p></li>
<li><p>Comandos R:<code>plot(as.ts(y))</code></p></li>
</ul>
<div id="ejemplo" class="section level4">
<h4>Ejemplo</h4>
<p>Datos mensuales de CO2 (ppm) en el ambiente entre enero de 1990 y diciembre de 1997</p>
<pre class="r"><code>load(&quot;data/co2.RData&quot;)
t &lt;- seq(1990, by=1/12, length=length(co2$y))
y &lt;- co2$y

plot(as.ts(y))</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Es habitual que este tipo de análisis se realice sobre los residuos de un modelo de regresión (e.g. <code>datos &lt;- residuals(modelo)</code>)</p>
<pre class="r"><code>modelo &lt;- lm(y ~ t, data = co2)
plot(y ~ t, data = co2)
abline(modelo)</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>r &lt;- residuals(modelo)
plot(as.ts(r))</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-5-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>En este caso se observa una componente estacional (anual), habría que incluirla en la tendencia. Por ejemplo:</p>
<pre class="r"><code>modelo &lt;- lm(y ~ t + as.factor(month), data = co2)
plot(y ~ t, data = co2)
lines(t, predict(modelo))</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>r &lt;- residuals(modelo)
plot(as.ts(r))</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-6-2.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="dependencia" class="section level4">
<h4>Dependencia</h4>
<p>Este gráfico también podría servir para detectar dependencia temporal:</p>
<ul>
<li><p>Valores próximos muy parecidos (valores grandes seguidos de grandes y viceversa) indicarían una posible dependencia positiva.</p></li>
<li><p>Valores próximos dispares (valores grandes seguidos de pequeños y viceversa) indicarían una posible dependencia negativa.</p></li>
</ul>
<pre class="r"><code>old.par &lt;- par(mfrow = c(1, 3))
plot(y2, type = &#39;l&#39;, ylab = &#39;&#39;, main = &#39;Dependencia positiva&#39;)
plot(y1, type = &#39;l&#39;, ylab = &#39;&#39;, main = &#39;Independencia&#39;)
y3 &lt;- y2 * c(1, -1)
plot(y3, type = &#39;l&#39;, ylab = &#39;&#39;, main = &#39;Dependencia negativa&#39;)</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-7-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(old.par)</code></pre>
<p>pero suele ser preferible emplear un gráfico de dispersión retardado.</p>
</div>
</div>
<div id="grafico-de-dispersion-retardado" class="section level2">
<h2>Gráfico de dispersion retardado</h2>
<p>El gráfico de dispersión <span class="math inline">\(\{(Y_{i},Y_{i+1}) : i = 1, \ldots, n-1 \}\)</span> permite detectar dependencias a un retardo (relaciones entre valores separados por un instante)</p>
<ul>
<li>Comando R:<code>plot(y[-length(y)], y[-1], xlab = &quot;Y_t&quot;, ylab = &quot;Y_t+1&quot;)</code></li>
</ul>
<pre class="r"><code>old.par &lt;- par(mfrow = c(1, 3))
plot(y2[-length(y2)], y2[-1], xlab = &quot;Y_t&quot;, ylab = &quot;Y_t+1&quot;, main = &#39;Dependencia positiva&#39;)
plot(y1[-length(y1)], y1[-1], xlab = &quot;Y_t&quot;, ylab = &quot;Y_t+1&quot;, main = &#39;Independencia&#39;)
plot(y3[-length(y3)], y3[-1], xlab = &quot;Y_t&quot;, ylab = &quot;Y_t+1&quot;, main = &#39;Dependencia negativa&#39;)</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-8-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(old.par)</code></pre>
<p>Se puede generalizar al gráfico <span class="math inline">\(\{(Y_{i},Y_{i+k}) : i = 1, \ldots, n-k \}\)</span> que permite detectar dependencias a <span class="math inline">\(k\)</span> retardos (separadas <span class="math inline">\(k\)</span> instantes).</p>
<div id="ejemplo-residuos-mediciones-co2" class="section level4">
<h4>Ejemplo: residuos mediciones co2</h4>
<pre class="r"><code># Gráfico de dispersion retardado
plot(r[-length(r)], r[-1], xlab = &quot;Y_t&quot;, ylab = &quot;Y_t+1&quot;)</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>El correspondiente coeficiente de correlación es una medida numérica del grado de relación lineal (denominado autocorrelación de orden 1).</p>
<pre class="r"><code>cor(r[-length(r)], r[-1])</code></pre>
<pre><code>## [1] 0.8768295</code></pre>
</div>
</div>
<div id="el-correlograma" class="section level2">
<h2>El correlograma</h2>
<p>Para estudiar si el grado de relación (lineal) entre <span class="math inline">\(Y_{i}\)</span> e <span class="math inline">\(Y_{i+k}\)</span> podemos utilizar el coeficiente de correlación:</p>
<p><span class="math display">\[\rho\left(  Y_{i},Y_{i+k}\right)  =\frac{Cov\left(  Y_{i},Y_{i+k}\right)    }
{\sigma\left(  Y_{i}\right)  \sigma\left(  Y_{i+k}\right)  }\]</span></p>
<ul>
<li><p>En el caso de datos homogéneos (estacionarios): <span class="math display">\[\rho\left(  Y_{i},Y_{i+k}\right)  \equiv\rho\left(  k\right)\]</span> denominada <strong>función de autocorrelación</strong> simple (fas) o correlograma.</p></li>
<li><p>Su estimador es el correlograma muestral: <span class="math display">\[r(k)=\frac{\sum_{i=1}^{n-k}(Y_{i}-\overline{Y})(Y_{i+k}-\overline{Y})}
{\sum_{i=1}^{n}(Y_{i}-\overline{Y})^{2}}\]</span></p></li>
<li><p>Comando R:<code>acf(y)</code></p></li>
</ul>
<p>En caso de independencia es de esperar que las autocorrelaciones muestrales sean próximas a cero (valores “grandes” indicarían dependencia positiva o negativa según el signo).</p>
<pre class="r"><code>old.par &lt;- par(mfrow = c(1, 3))
acf(y1, main = &#39;Independencia&#39;)
acf(y2, main = &#39;Dependencia positiva&#39;)
acf(y3, main = &#39;Dependencia negativa&#39;)</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-11-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(old.par)</code></pre>
<p>Suponiendo normalidad e independencia, asintóticamente: <span class="math display">\[r(k)\underset{aprox.}{\sim}N\left(  \rho(k),\frac{1}{n}\right)\]</span></p>
<ul>
<li><p>Si el tamaño muestral es grande, podríamos aceptar <span class="math inline">\(H_{0}:\)</span> <span class="math inline">\(\rho\left( k\right) =0\)</span> si:<span class="math display">\[|r(k)|&lt;\dfrac{2}{\sqrt{n}}\]</span></p></li>
<li><p>En el <strong>gráfico de autocorrelaciones muestrales</strong> (también denominado correlograma) se representan las estimaciones <span class="math inline">\(r(k)\)</span> de las autocorrelaciones correspondientes a los primeros retardos (típicamente <span class="math inline">\(k&lt;n/4\)</span>) y las correspondientes bandas de confianza (para detectar dependencias significativas).</p></li>
</ul>
<div id="ejemplo-residuos-mediciones-co2-1" class="section level4">
<h4>Ejemplo: residuos mediciones co2</h4>
<pre class="r"><code>acf(r)  # correlaciones</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-12-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><br></p>
<p>La función <code>acf</code> también permite estimar el covariograma.</p>
<pre class="r"><code>covar &lt;- acf(y2, type = &quot;covariance&quot;)</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-13-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>En estadística espacial en lugar del covariograma se suele emplear el semivariograma <span class="math inline">\(\gamma(k) = C(0) - C(k)\)</span>:</p>
<pre class="r"><code>plot(covar, type = &#39;l&#39;, ylab = &#39;&#39;, main = &#39;Covariograma y semivariograma (estimados)&#39;, col = &#39;blue&#39;)
semivar &lt;- covar$acf[1] - covar$acf
lags &lt;- covar$lag
lines(lags, semivar, col = &#39;red&#39;)
legend(&quot;bottomright&quot;, legend = c(&quot;covariograma&quot;, &quot;semivariograma&quot;), col = c(&#39;blue&#39;, &#39;red&#39;), lty = 1)</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
<div id="contrastes-de-hipotesis" class="section level1">
<h1>Contrastes de hipótesis</h1>
<div id="test-de-rachas" class="section level2">
<h2>Test de rachas</h2>
<p>Permite contrastar si el orden de aparición de dos valores de una variable dicotómica es aleatorio. Supongamos que <span class="math inline">\(X\)</span> toma los valores <span class="math inline">\(+\)</span> y <span class="math inline">\(-\)</span> y que observamos una muestra del tipo: <span class="math display">\[++++---+++--++++++----\]</span> y nos interesa contrastar:</p>
<p><span class="math display">\[\left\{ \begin{array}[c]{l}
    H_{0}:\mathit{La\ muestra\ es\ aleatoria}\\
    H_{1}:\mathit{La\ muestra\ no\ es\ aleatoria}
\end{array}
\right.\]</span></p>
<p>Una <strong>racha</strong> es una secuencia de observaciones iguales (o similares): <span class="math display">\[\underbrace{++++}_{1}\underbrace{---}_{2}\underbrace{+++}_{3}
\underbrace{--}_{4}\underbrace{++++++}_{5}\underbrace{----}_{6}\]</span></p>
<ul>
<li><p>Una muestra con <strong>muchas o pocas rachas</strong> sugeriría que la muestra no es aleatoria (con dependencia negativa o positiva, respec.).</p></li>
<li><p>Estadístico del contraste: <span class="math display">\[R=\text{&quot;Nº total de rachas en la muestra&quot;}\]</span></p></li>
<li><p>Bajo la hipótesis nula de aleatoriedad: <span class="math display">\[R\underset{aprox.}{\sim}N\left(  1+\frac{2n_{1}n_{2}}{n},
\frac{2n_{1}n_{2}(2n_{1}n_{2}-n)}{n^{2}(n-1)}\right)\]</span> siendo <span class="math inline">\(n_{1}\)</span> y <span class="math inline">\(n_{2}\)</span> el nº de signos <span class="math inline">\(+\)</span> y <span class="math inline">\(-\)</span> en la muestra, respectivamente (<span class="math inline">\(n_{1}+n_{2}=n\)</span>). Para tamaños muéstrales pequeños (<span class="math inline">\(n&lt;40\)</span>), esta aproximación no es buena y conviene utilizar la distribución exacta (o utilizar corrección por continuidad). Los valores críticos de esta distribución están tabulados.</p></li>
</ul>
<p><br></p>
<p>Este contraste se emplea también para variables continuas, se fija un punto de corte para dicotomizarlas. Normalmente se toma como punto de corte la mediana.</p>
<ul>
<li><p>En este caso si <span class="math inline">\(k=n_{1}\)</span> (<span class="math inline">\(\simeq n_{2}\)</span>): <span class="math display">\[R\underset{aprox.}{\sim}N\left(  k+1,\frac{k(k-1)}{2k-1}\right)\]</span></p></li>
<li><p>Se rechaza la hipótesis nula de aleatoriedad si el número de rachas es significativamente pequeño o grande.</p></li>
<li><p>Si el tamaño muestral es grande, el <span class="math inline">\(p\)</span>-valor será:<span class="math display">\[p\simeq2\cdot P\left(  Z\geq\left\vert \frac{R-E(R)}{\sqrt{Var(R)}}\right\vert
\right)\]</span></p></li>
<li><p>Comandos R:</p></li>
</ul>
<pre class="r"><code>     library(tseries)
     runs.test(as.factor(y &gt; median(y)))</code></pre>
<div id="ejemplo-residuos-mediciones-co2-2" class="section level4">
<h4>Ejemplo: residuos mediciones co2</h4>
<pre class="r"><code>library(tseries)
runs.test(as.factor(r &gt; median(r)))</code></pre>
<pre><code>## 
##  Runs Test
## 
## data:  as.factor(r &gt; median(r))
## Standard Normal = -7.1822, p-value = 6.858e-13
## alternative hypothesis: two.sided</code></pre>
</div>
</div>
<div id="el-contraste-de-ljung-box" class="section level2">
<h2>El contraste de Ljung-Box</h2>
<p>Es un test muy utilizado (en series de tiempo) para contrastar la hipótesis de independencia.</p>
<p>Se contrasta la hipótesis nula de que las primeras <span class="math inline">\(m\)</span> autocorrelaciones son cero: <span class="math display">\[\left\{\begin{array}[c]{l}
    H_{0}:\rho_{1}=\rho_{2}=\ldots=\rho_{m}=0\\
    H_{1}:\rho_{i}\neq0\text{ para algún } i
\end{array}
\right.\]</span></p>
<ul>
<li><p>Se elige un <span class="math inline">\(m\)</span> tal que la estimación <span class="math inline">\(r(m)\)</span> de <span class="math inline">\(\rho_{m}=\rho(m)\)</span> sea “fiable” (e.g. <span class="math inline">\(10\log_{10}n\)</span>).</p></li>
<li><p>El estadístico del contraste:<span class="math display">\[Q=n(n+2)\sum_{k=1}^{m}\frac{r(k)^{2}}{n-k}\underset{aprox.}{\sim}\chi
_{m-1}^{2}\text{, si }H_{0}\text{ es cierta.}\]</span></p></li>
<li><p>Se rechaza <span class="math inline">\(H_{0}\)</span> si el valor observado es grande (<span class="math inline">\(Q\geq \chi_{m-1,1-\alpha}^{2}\)</span>):<span class="math display">\[p=P\left(  {\chi_{m-1}^{2}}\geq Q\right)\]</span></p></li>
<li><p>Comandos R:</p></li>
</ul>
<pre class="r"><code>    Box.test(y, type=Ljung)
    Box.test(y, lag, type=Ljung)</code></pre>
<div id="ejemplo-residuos-mediciones-co2-3" class="section level4">
<h4>Ejemplo: residuos mediciones co2</h4>
<pre class="r"><code>Box.test(r, type=&quot;Ljung&quot;) # Contrasta si la primera autocorrelación es nula </code></pre>
<pre><code>## 
##  Box-Ljung test
## 
## data:  r
## X-squared = 67.568, df = 1, p-value = 2.22e-16</code></pre>
<pre class="r"><code>Box.test(y, lag=10, type=&quot;Ljung&quot;) # Contrasta si las 10 primeras autocorrelaciones son nulas</code></pre>
<pre><code>## 
##  Box-Ljung test
## 
## data:  y
## X-squared = 271.5, df = 10, p-value &lt; 2.2e-16</code></pre>
<p>NOTA: Para contrastar que la primera autocorrelación es cero, teniendo en cuenta además que los valores son residuos, sería preferible emplear el test de Durbin-Watson visto antes:</p>
<pre class="r"><code>library(lmtest)
dwtest(modelo, alternative= &quot;two.sided&quot;)</code></pre>
<pre><code>## 
##  Durbin-Watson test
## 
## data:  modelo
## DW = 0.23671, p-value &lt; 2.2e-16
## alternative hypothesis: true autocorrelation is not 0</code></pre>
</div>
</div>
</div>
<div id="ejemplo-adicional-analisis-de-series-temporales" class="section level1">
<h1>Ejemplo adicional: Análisis de series temporales</h1>
<p>En este caso sería recomendable analizar los datos como una serie temporales. Se trataría de modelar los componentes de la serie de tiempo:</p>
<pre class="r"><code>plot(decompose(co2$y.ts))</code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Para ello se suele emplear modelos ARIMA, e.g.:</p>
<pre class="r"><code>library(forecast)
fit &lt;- auto.arima(co2$y.ts)
plot(forecast(fit, h = 24, level = 95), shaded = FALSE)           </code></pre>
<p><img src="/post/2017-10-23-Diagnosis_independencia_files/figure-html/unnamed-chunk-21-1.png" width="672" style="display: block; margin: auto;" /></p>
<div id="bibliografia" class="section level4">
<h4>Bibliografía:</h4>
<ul>
<li><p>Cryer, J.D. y Chan, K.S. (2008). <em>Time Series Analysis. With Applications in R</em>. Springer.</p></li>
<li><p>Shumway, R.H. y Stoffer, D.S. (2006). <em>Time Series Analysis and Its Applications. With R Examples</em>. Springer.</p></li>
</ul>
</div>
</div>

    </div>

    
    
    
    <div class="article-tags">
      
      <a class="btn btn-primary btn-outline" href="/tags/geoestad%c3%adstica">Geoestadística</a>
      
      <a class="btn btn-primary btn-outline" href="/tags/regresion">regresion</a>
      
    </div>
    
    

  </div>

</article>



<div class="article-container article-widget">
  <div class="hr-light"></div>
  <h3></h3>
  <ul>
    
    <li><a href="/post/introducci%C3%B3n-a-la-geoestad%C3%ADstica-con-geor/">Introducción a la Geoestadística con geoR</a></li>
    
    <li><a href="/post/2015-07-23-r-rmarkdown/">Hello R Markdown</a></li>
    
  </ul>
</div>




<div class="article-container">
  

</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2017 Ruben Fernandez-Casal &middot; 

      Powered by <a href="https://bookdown.org/yihui/blogdown" target="_blank">blogdown</a> 
      and the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic
      theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>

    

    
    

    
    <script async defer src="//maps.googleapis.com/maps/api/js"></script>
    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gmaps.js/0.4.25/gmaps.min.js" integrity="sha256-7vjlAeb8OaTrCXZkCNun9djzuB2owUsaO72kXaFDBJs=" crossorigin="anonymous"></script>
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

